{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VEmNTpf44r2t"
   },
   "source": [
    "# **Importing All Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bbvSKZZMxcjS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import f1_score\n",
    "import texttable as tt\n",
    "from collections import Counter\n",
    "from sklearn import svm\n",
    "from highcharts import highcharts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below dictionary for replacing integer classes with string names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dic = {1: 'WALKING',           \n",
    "2: 'WALKING_UPSTAIRS',  \n",
    "3: 'WALKING_DOWNSTAIRS',\n",
    "4: 'SITTING',           \n",
    "5: 'STANDING',          \n",
    "6: 'LAYING',            \n",
    "7: 'STAND_TO_SIT',      \n",
    "8: 'SIT_TO_STAND',      \n",
    "9: 'SIT_TO_LIE',        \n",
    "10: 'LIE_TO_SIT',        \n",
    "11: 'STAND_TO_LIE',      \n",
    "12: 'LIE_TO_STAND'      \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading all the required data-sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WeyCxF3G0CRO"
   },
   "outputs": [],
   "source": [
    "train_subject = pd.read_csv(r'C:\\Users\\HassaanSeeker\\Desktop\\data\\Train\\subject_id_train.txt',\n",
    "                            sep = ' ', header = None)\n",
    "test_subject = pd.read_csv(r'C:\\Users\\HassaanSeeker\\Desktop\\data\\Test\\subject_id_test.txt',\n",
    "                           sep = ' ', header = None)\n",
    "train_data = pd.read_csv(r'C:\\Users\\HassaanSeeker\\Desktop\\data\\Train\\X_train.txt', \n",
    "                         sep = ' ', header = None)\n",
    "train_target = pd.read_csv(r'C:\\Users\\HassaanSeeker\\Desktop\\data\\Train\\y_train.txt',\n",
    "                           sep = ' ', header = None)\n",
    "test_data = pd.read_csv(r'C:\\Users\\HassaanSeeker\\Desktop\\data\\Test\\X_test.txt',\n",
    "                        sep = ' ', header = None)\n",
    "test_target = pd.read_csv(r'C:\\Users\\HassaanSeeker\\Desktop\\data\\Test\\y_test.txt',\n",
    "                          sep = ' ', header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging both training and test data-sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "THvQea7ASyOZ"
   },
   "outputs": [],
   "source": [
    "total_data = pd.concat([train_data, test_data], axis = 0).reset_index(\n",
    "                                    drop = True)\n",
    "total_target = pd.concat([train_target, test_target], axis = 0).reset_index(\n",
    "                                    drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting count for all the activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_count = Counter(total_target.replace(features_dic)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List creation for bar-chart graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_count_name = []\n",
    "features_count_count = []\n",
    "\n",
    "for key, values in features_count.items():\n",
    "    features_count_name.append(key)\n",
    "    features_count_count.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe style=\"border:0;outline:none;overflow:hidden\" srcdoc=\"&lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot; /&gt; &lt;link href=&quot;https://www.highcharts.com/highslide/highslide.css&quot; rel=&quot;stylesheet&quot; /&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;https://code.highcharts.com/6/highcharts.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;https://code.highcharts.com/6/highcharts-more.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;https://code.highcharts.com/6/modules/heatmap.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;https://code.highcharts.com/6/modules/exporting.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body style=&quot;margin:0;padding:0&quot;&gt; &lt;div id=&quot;container&quot; style=&quot;width:750px;height:600px;&quot;&gt;Loading....&lt;/div&gt; &lt;script&gt; $(function(){ Highcharts.setOptions({&quot;global&quot;: {}, &quot;lang&quot;: {}}); var option = {&quot;chart&quot;: {&quot;renderTo&quot;: &quot;container&quot;, &quot;width&quot;: 750, &quot;height&quot;: 600}, &quot;colors&quot;: {}, &quot;credits&quot;: {&quot;enabled&quot;: false}, &quot;drilldown&quot;: {}, &quot;exporting&quot;: {}, &quot;labels&quot;: {}, &quot;legend&quot;: {&quot;layout&quot;: &quot;vertical&quot;, &quot;align&quot;: &quot;right&quot;, &quot;verticalAlign&quot;: &quot;top&quot;, &quot;x&quot;: -40, &quot;y&quot;: 80, &quot;floating&quot;: true, &quot;borderWidth&quot;: 1, &quot;backgroundColor&quot;: ((Highcharts.theme &amp;&amp; Highcharts.theme.legendBackgroundColor) || &#x27;#FFFFFF&#x27;), &quot;shadow&quot;: true}, &quot;loading&quot;: {}, &quot;navigation&quot;: {}, &quot;pane&quot;: {}, &quot;plotOptions&quot;: {&quot;bar&quot;: {&quot;dataLabels&quot;: {&quot;enabled&quot;: true}}}, &quot;series&quot;: {}, &quot;subtitle&quot;: {&quot;text&quot;: &quot;&quot;}, &quot;title&quot;: {&quot;text&quot;: &quot;Stacked bar chart&quot;}, &quot;tooltip&quot;: {&quot;valueSuffix&quot;: &quot;&quot;}, &quot;xAxis&quot;: {&quot;categories&quot;: [&quot;STANDING&quot;, &quot;STAND_TO_SIT&quot;, &quot;SITTING&quot;, &quot;SIT_TO_STAND&quot;, &quot;STAND_TO_LIE&quot;, &quot;LAYING&quot;, &quot;LIE_TO_SIT&quot;, &quot;SIT_TO_LIE&quot;, &quot;LIE_TO_STAND&quot;, &quot;WALKING&quot;, &quot;WALKING_DOWNSTAIRS&quot;, &quot;WALKING_UPSTAIRS&quot;], &quot;title&quot;: {&quot;text&quot;: null}}, &quot;yAxis&quot;: {&quot;min&quot;: 0, &quot;title&quot;: {&quot;text&quot;: &quot;Count&quot;, &quot;align&quot;: &quot;high&quot;}, &quot;labels&quot;: {&quot;overflow&quot;: &quot;justify&quot;}}}; var chart = new Highcharts.Chart(option); var data = [{&quot;data&quot;: [1979, 70, 1801, 33, 139, 1958, 85, 107, 84, 1722, 1407, 1544], &quot;type&quot;: &quot;bar&quot;, &quot;name&quot;: &quot;Count for different activities&quot;}]; var dataLen = data.length; for (var ix = 0; ix &lt; dataLen; ix++) { chart.addSeries(data[ix]); } }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;\" height=600 width=750></iframe>"
      ],
      "text/plain": [
       "<highcharts.highcharts.highcharts.Highchart at 0x2b978b8be80>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from highcharts import Highchart\n",
    "H = Highchart(width=750, height=600)\n",
    "\n",
    "data1 = features_count_count\n",
    "\n",
    "options = {\n",
    "\t'title': {\n",
    "        'text': 'Stacked bar chart'\n",
    "    },\n",
    "    'subtitle': {\n",
    "        'text': ''\n",
    "    },\n",
    "    'xAxis': {\n",
    "        'categories': features_count_name,\n",
    "        'title': {\n",
    "            'text': None\n",
    "        }\n",
    "    },\n",
    "    'yAxis': {\n",
    "        'min': 0,\n",
    "        'title': {\n",
    "            'text': 'Count',\n",
    "            'align': 'high'\n",
    "        },\n",
    "        'labels': {\n",
    "            'overflow': 'justify'\n",
    "        }\n",
    "    },\n",
    "    'tooltip': {\n",
    "        'valueSuffix': ''\n",
    "    },\n",
    "    'legend': {\n",
    "        'layout': 'vertical',\n",
    "        'align': 'right',\n",
    "        'verticalAlign': 'top',\n",
    "        'x': -40,\n",
    "        'y': 80,\n",
    "        'floating': True,\n",
    "        'borderWidth': 1,\n",
    "        'backgroundColor': \"((Highcharts.theme && Highcharts.theme.legendBackgroundColor) || '#FFFFFF')\",\n",
    "        'shadow': True\n",
    "    },\n",
    "    'credits': {\n",
    "        'enabled': False\n",
    "    },\n",
    "    'plotOptions': {\n",
    "        'bar': {\n",
    "            'dataLabels': {\n",
    "                'enabled': True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "H.set_dict_options(options)\n",
    "\n",
    "H.add_data_set(data1, 'bar', 'Count for different activities')\n",
    "\n",
    "H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Above Figure showing standing and laying as the most activities done my the subjects "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for checking null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oreGnuBr_C6a"
   },
   "outputs": [],
   "source": [
    "def check_for_null_values(data):\n",
    "  return data.loc[data.isnull().any(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardinzing All Data-Points\n",
    " Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scl = StandardScaler()\n",
    "total_data = scl.fit_transform(total_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "\n",
    "Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space.\n",
    "Having too many dimensions (features) in your data causes noise and difficulties (it can be sound, picture or context). This specifically get worst when features have different scales (e.g. weight,length,area,speed, power, temperature,volume,time,cell number, etc. )\n",
    "We do this by reducing the dimension i.e. the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gulcM_89RMPc"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 0.9, random_state = 3)\n",
    "total_data = pca.fit_transform(total_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data-Set into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNqia63baqxK"
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(total_data,\n",
    "                                     total_target, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for model_selection for different classifcation models\n",
    "### Models Used:\n",
    "    Multi-LogisticRegression\n",
    "    LightGBM\n",
    "    SupportVectorMachine(LinearSVC)\n",
    "    SupportVectorMachine(SVC => onevsone) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pbkqurrgWWji"
   },
   "outputs": [],
   "source": [
    "def model_selection(train_X, test_X, train_Y, test_Y):\n",
    "  \n",
    "  models_accuracy_score = {}\n",
    "  # Multinomial Logistic Regression\n",
    "  softmax_reg = LogisticRegression(multi_class = \"multinomial\", solver=\"lbfgs\", C = 1)\n",
    "  softmax_reg.fit(train_X, train_Y)\n",
    "\n",
    "  # score_softmax = accuracy_score(y_true = test_Y, y_pred = softmax_reg.predict(test_X))\n",
    "  \n",
    "  accuracy_metrics(test_Y, softmax_reg.predict(test_X), 'Multi-LogisticRegression')\n",
    "\n",
    "  \n",
    "  # LightGBMBOOSTING Algorithm\n",
    "  \n",
    "  lgbm = LGBMClassifier(n_estimators = 500, random_state = 3)\n",
    "  lgbm = lgbm.fit(train_X, train_Y)\n",
    "\n",
    "  accuracy_metrics(test_Y, lgbm.predict(test_X), 'lgbm')\n",
    "    \n",
    "  lin_clf = svm.LinearSVC()\n",
    "  lin_clf.fit(train_X, train_Y)\n",
    "    \n",
    "  accuracy_metrics(test_Y, lin_clf.predict(test_X), 'LinearSVC')\n",
    "  \n",
    "  clf = svm.SVC(kernel = 'rbf', gamma = 'scale', decision_function_shape='ovo', C = 1)\n",
    "  clf.fit(train_X, train_Y)\n",
    "  accuracy_metrics(test_Y, clf.predict(test_X), 'SVC-OVO')\n",
    "  \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for accessing the accuracy of classification models\n",
    " ### Metrics Selected:\n",
    " ####      sklearn.accuracy_score: \n",
    " The accuracy_score function computes the accuracy, either the fraction (default) or the count (normalize=False) of correct predictions.\n",
    " In multilabel classification, the function returns the subset accuracy. If the entire set of predicted labels for a sample strictly match with the true set of   labels, then the subset accuracy is 1.0; otherwise it is 0.0. https://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score\n",
    " ####      Precision \n",
    " ####      Recall\n",
    " ####      F1-Score\n",
    "https://en.wikipedia.org/wiki/Precision_and_recall#Definition_%28classification_context%29\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metrics(Y_true, Y_pred, model):\n",
    "    tab = tt.Texttable()\n",
    "    Accuracy_metrics_Score = {}\n",
    "    \n",
    "    Accuracy_Score = accuracy_score(y_true = Y_true, y_pred = Y_pred)\n",
    "    \n",
    "    F1_Score_each_class = f1_score(Y_true, Y_pred, average = None)\n",
    "    F1_Score_all_class = f1_score(Y_true, Y_pred, average = 'micro')\n",
    "    \n",
    "    # precisions, recalls, thresholds = precision_recall_curve(Y_true, Y_pred, average = 'micro')\n",
    "    # plot_precision_recall_vs_threshold(precision, recalls, thresholds)\n",
    "    \n",
    "    precision, recall, fscore, support = score(Y_true, Y_pred)\n",
    "    \n",
    "    # Accuracy_metrics_Score.update({model: Accuracy_Score})\n",
    "    # Accuracy_metrics_Score.update({model: F1_Score})\n",
    "\n",
    "    print(model,\"accuracy_score : \", Accuracy_Score)\n",
    "    print(model, \"F1_Score for all classes: \", F1_Score_all_class)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(precision)\n",
    "    \n",
    "    headings = ['Precision', 'Recall', 'Fscore', 'Support']\n",
    "    tab.header(headings)\n",
    "    for row in zip(precision, recall, fscore, support):\n",
    "        tab.add_row(row)\n",
    "    s = tab.draw()\n",
    "    print( s )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "_6nZzRaCWSji",
    "outputId": "10bff31b-8a69-4422-c109-c802c3b1ec4d"
   },
   "outputs": [],
   "source": [
    "model_selection(train_X, test_X, train_Y, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### From the above results Support vector machine with support vector classification implementation in sklearn is showing the best accuracy of all other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for parameter tuning using grid-search\n",
    "    As support-vector-classification is showing the best accuracy doing parameter tuning for it in below function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_svm(train_X, train_Y, test_X, test_Y):\n",
    "    accuracy_dic = {}\n",
    "    parameters = []\n",
    "    c = [0.1, 1, 10, 100]\n",
    "    kernel = ['poly', 'rbf']\n",
    "    degree = [0, 1, 2, 3, 4, 5, 6]\n",
    "    for i in range(0, len(c)):\n",
    "        \n",
    "        for j in range(0, len(kernel)):\n",
    "            \n",
    "            for k in range(0, len(degree)):\n",
    "                \n",
    "                clf = svm.SVC(kernel = kernel[j], gamma = 'scale', \n",
    "                              decision_function_shape='ovo', C = c[i], degree = degree[k])\n",
    "                \n",
    "                parameters.append(c[i])\n",
    "                parameters.append(kernel[j])\n",
    "                parameters.append(degree[k])\n",
    "                \n",
    "                clf.fit(train_X, train_Y)\n",
    "                accuracy_metrics(test_Y, clf.predict(test_X), 'SVC-OVO')\n",
    "                Accuracy_Score = accuracy_score(y_true = test_Y, y_pred = clf.predict(test_X))\n",
    "                accuracy_dic.update({Accuracy_Score: parameters})\n",
    "                \n",
    "                parameters = []\n",
    "\n",
    "    return accuracy_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = grid_search_svm(train_X, train_Y, test_X, test_Y)\n",
    "\n",
    "## Below implementation for best parameters\n",
    "a = []\n",
    "for key, values in x.items():\n",
    "    if key > 0.95:\n",
    "        print(key, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Selection\n",
    "##### Below after grid search best paramaters for svm.svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HassaanSeeker\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC-OVO accuracy_score :  0.9542627149652396\n",
      "SVC-OVO F1_Score for all classes:  0.9542627149652396\n",
      "[0.99537037 0.98950131 0.90740741 0.95465394 0.93787575 0.99606299\n",
      " 0.89473684 1.         0.75       0.68181818 0.62857143 0.61538462]\n",
      "+-----------+--------+--------+---------+\n",
      "| Precision | Recall | Fscore | Support |\n",
      "+===========+========+========+=========+\n",
      "| 0.995     | 0.991  | 0.993  | 434     |\n",
      "+-----------+--------+--------+---------+\n",
      "| 0.990     | 0.977  | 0.983  | 386     |\n",
      "+-----------+--------+--------+---------+\n",
      "| 0.907     | 0.994  | 0.949  | 345     |\n",
      "+-----------+--------+--------+---------+\n",
      "| 0.955     | 0.922  | 0.938  | 434     |\n",
      "+-----------+--------+--------+---------+\n",
      "| 0.938     | 0.959  | 0.948  | 488     |\n",
      "+-----------+--------+--------+---------+\n",
      "| 0.996     | 0.998  | 0.997  | 507     |\n",
      "+-----------+--------+--------+---------+\n",
      "| 0.895     | 0.739  | 0.810  | 23      |\n",
      "+-----------+--------+--------+---------+\n",
      "| 1         | 0.778  | 0.875  | 9       |\n",
      "+-----------+--------+--------+---------+\n",
      "| 0.750     | 0.441  | 0.556  | 34      |\n",
      "+-----------+--------+--------+---------+\n",
      "| 0.682     | 0.750  | 0.714  | 20      |\n",
      "+-----------+--------+--------+---------+\n",
      "| 0.629     | 0.595  | 0.611  | 37      |\n",
      "+-----------+--------+--------+---------+\n",
      "| 0.615     | 0.500  | 0.552  | 16      |\n",
      "+-----------+--------+--------+---------+\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel = 'rbf', gamma = 'scale', decision_function_shape='ovo',\n",
    "              C = 10, degree = 6)\n",
    "clf.fit(train_X, train_Y)\n",
    "accuracy_metrics(test_Y, clf.predict(test_X), 'SVC-OVO')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Words and Improvements\n",
    "There is a lot of room for further improvement specifically if we have more data some deep-leerning classifcation algorithms can also be implemented. But usually deep-learning algorithms like LSTMS, RNN require more than 30,000 data points. Since simple classification algorithms are giving resonaby\n",
    "good accuracy no need to investigate for deep-lerning option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AIVENTURE_TASK",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
